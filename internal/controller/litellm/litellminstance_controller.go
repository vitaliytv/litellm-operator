/*
Copyright 2025.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

// Package litellm provides the controller implementation for LiteLLMInstance resources.
// This package contains the reconciliation logic for managing LiteLLM proxy instances
// in Kubernetes, including the creation and management of ConfigMaps, Secrets,
// Deployments, Services, and Ingress resources.
package litellm

import (
	"context"
	"errors"
	"fmt"
	"regexp"
	"strings"
	"time"

	"gopkg.in/yaml.v2"

	"k8s.io/apimachinery/pkg/api/meta"
	"k8s.io/apimachinery/pkg/runtime"
	ctrl "sigs.k8s.io/controller-runtime"
	"sigs.k8s.io/controller-runtime/pkg/client"
	"sigs.k8s.io/controller-runtime/pkg/controller/controllerutil"
	logf "sigs.k8s.io/controller-runtime/pkg/log"

	litellmv1alpha1 "github.com/bbdsoftware/litellm-operator/api/litellm/v1alpha1"
	"github.com/bbdsoftware/litellm-operator/internal/controller/base"
	"github.com/bbdsoftware/litellm-operator/internal/controller/common"
	"github.com/bbdsoftware/litellm-operator/internal/util"
	"github.com/google/uuid"
	"github.com/prometheus/client_golang/prometheus"
	appsv1 "k8s.io/api/apps/v1"
	corev1 "k8s.io/api/core/v1"
	networkingv1 "k8s.io/api/networking/v1"
	rbacv1 "k8s.io/api/rbac/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/util/intstr"
	"sigs.k8s.io/controller-runtime/pkg/metrics"
)

var (
	// managed resource metrics
	// Indicates whether a specific managed resource for a LiteLLMInstance is active (1) or inactive (0)
	managedResourceActive = prometheus.NewGaugeVec(
		prometheus.GaugeOpts{
			Name: "litellm_operator_managed_resource_active",
			Help: "Active (1) or inactive (0) state for a managed resource belonging to a LiteLLMInstance",
		},
		[]string{"instance", "namespace", "resource"},
	)

	// Per-instance/resource/status metric. Value is 1 for the current status for that instance+resource, 0 otherwise.
	managedResourceStatus = prometheus.NewGaugeVec(
		prometheus.GaugeOpts{
			Name: "litellm_operator_managed_resource_status",
			Help: "Status of a managed resource for a LiteLLMInstance. Use label 'status' to partition (e.g. inactive,missing,created,ready,not_ready)",
		},
		[]string{"instance", "namespace", "resource", "status"},
	)
)

func init() {
	// Register LiteLLM instance specific metrics with the global prometheus registry
	metrics.Registry.MustRegister(managedResourceActive, managedResourceStatus)
}

// recordReconcileError increments the overall error counter and the per-kind counter.
// It makes a best-effort attempt to classify the error into a short label.

const (
	// Container configuration constants
	ContainerPort = 4000                                    // Port that the LiteLLM container listens on
	ServicePort   = 4000                                    // Port that the Service exposes
	ConfigPath    = "/etc/litellm/proxy_server_config.yaml" // Path to config file in container

	// Health check paths for container probes
	LivenessPath  = "/health/liveness"  // Path for liveness probe
	ReadinessPath = "/health/readiness" // Path for readiness probe

	// Condition types and reasons
	CondTypeConfigMapReady  = "ConfigMapReady"
	CondTypeSecretReady     = "SecretReady"
	CondTypeDeploymentReady = "DeploymentReady"
	CondTypeServiceReady    = "ServiceReady"
	CondTypeIngressReady    = "IngressReady"
	CondTypeReady           = "Ready"

	ReasonConfigMapReady     = "ConfigMapReady"
	ReasonConfigMapNotReady  = "ConfigMapNotReady"
	ReasonSecretReady        = "SecretReady"
	ReasonSecretNotReady     = "SecretNotReady"
	ReasonDeploymentReady    = "DeploymentReady"
	ReasonDeploymentNotReady = "DeploymentNotReady"
	ReasonServiceReady       = "ServiceReady"
	ReasonServiceNotReady    = "ServiceNotReady"
	ReasonIngressReady       = "IngressReady"
	ReasonIngressNotReady    = "IngressNotReady"

	// Resource status constants for metrics
	StatusCreated  = "created"
	StatusReady    = "ready"
	StatusNotReady = "not_ready"
	StatusMissing  = "missing"
)

// LiteLLMInstanceReconciler reconciles a LiteLLMInstance object.
// It is responsible for creating and managing the Kubernetes resources required
// to run a LiteLLM proxy instance, including ConfigMaps, Secrets, Deployments,
// Services, and optionally Ingress resources.
type LiteLLMInstanceReconciler struct {
	*base.BaseController[*litellmv1alpha1.LiteLLMInstance]
	litellmResourceNaming *util.LitellmResourceNaming
}

type LiteLLMParamsYAML struct {
	ApiKey                           string                 `yaml:"api_key,omitempty"`
	ApiBase                          string                 `yaml:"api_base,omitempty"`
	AwsAccessKeyID                   string                 `yaml:"aws_access_key_id,omitempty"`
	AwsSecretAccessKey               string                 `yaml:"aws_secret_access_key,omitempty"`
	AwsRegionName                    string                 `yaml:"aws_region_name,omitempty"`
	AutoRouterConfigPath             string                 `yaml:"auto_router_config_path,omitempty"`
	AutoRouterConfig                 string                 `yaml:"auto_router_config,omitempty"`
	AutoRouterDefaultModel           string                 `yaml:"auto_router_default_model,omitempty"`
	AutoRouterEmbeddingModel         string                 `yaml:"auto_router_embedding_model,omitempty"`
	AdditionalProps                  map[string]interface{} `yaml:"additionalProps,omitempty"`
	ApiVersion                       string                 `yaml:"api_version,omitempty"`
	BudgetDuration                   string                 `yaml:"budget_duration,omitempty"`
	ConfigurableClientsideAuthParams []interface{}          `yaml:"configurable_clientside_auth_params,omitempty"`
	CustomLLMProvider                string                 `yaml:"custom_llm_provider,omitempty"`
	InputCostPerToken                float64                `yaml:"input_cost_per_token,omitempty"`
	InputCostPerPixel                float64                `yaml:"input_cost_per_pixel,omitempty"`
	InputCostPerSecond               float64                `yaml:"input_cost_per_second,omitempty"`
	LiteLLMTraceID                   string                 `yaml:"litellm_trace_id,omitempty"`
	LiteLLMCredentialName            string                 `yaml:"litellm_credential_name,omitempty"`
	MaxFileSizeMB                    int                    `yaml:"max_file_size_mb,omitempty"`
	MergeReasoningContentInChoices   bool                   `yaml:"merge_reasoning_content_in_choices,omitempty"`
	MockResponse                     string                 `yaml:"mock_response,omitempty"`
	Model                            string                 `yaml:"model"`
	MaxBudget                        float64                `yaml:"max_budget,omitempty"`
	MaxRetries                       int                    `yaml:"max_retries,omitempty"`
	Organization                     string                 `yaml:"organization,omitempty"`
	OutputCostPerToken               float64                `yaml:"output_cost_per_token,omitempty"`
	OutputCostPerSecond              float64                `yaml:"output_cost_per_second,omitempty"`
	OutputCostPerPixel               float64                `yaml:"output_cost_per_pixel,omitempty"`
	RegionName                       string                 `yaml:"region_name,omitempty"`
	RPM                              int                    `yaml:"rpm,omitempty"`
	StreamTimeout                    int                    `yaml:"stream_timeout,omitempty"`
	TPM                              int                    `yaml:"tpm,omitempty"`
	Timeout                          int                    `yaml:"timeout,omitempty"`
	UseInPassThrough                 bool                   `yaml:"use_in_pass_through,omitempty"`
	UseLiteLLMProxy                  bool                   `yaml:"use_litellm_proxy,omitempty"`
	VertexProject                    string                 `yaml:"vertex_project,omitempty"`
	VertexLocation                   string                 `yaml:"vertex_location,omitempty"`
	VertexCredentials                string                 `yaml:"vertex_credentials,omitempty"`
	WatsonxRegionName                string                 `yaml:"watsonx_region_name,omitempty"`
}

type ModelListItemYAML struct {
	ModelName     string            `yaml:"model_name"`
	LitellmParams LiteLLMParamsYAML `yaml:"litellm_params"`
}

type RouterSettingsYAML struct {
	Host     string `yaml:"host"`
	Port     string `yaml:"port"`
	Password string `yaml:"password,omitempty"`
}

type ProxyConfig struct {
	ModelList       []ModelListItemYAML `yaml:"model_list"`
	RouterSettings  RouterSettingsYAML  `yaml:"router_settings,omitempty"`
	GeneralSettings struct {
		AllowRequestsOnDBUnavailable bool `yaml:"allow_requests_on_db_unavailable"`
		StoreModelInDB               bool `yaml:"store_model_in_db"` //Needed to be able to store new models created via REST API
	} `yaml:"general_settings"`
}

func NewLiteLLMInstanceReconciler(c client.Client, scheme *runtime.Scheme) *LiteLLMInstanceReconciler {
	return &LiteLLMInstanceReconciler{
		BaseController: &base.BaseController[*litellmv1alpha1.LiteLLMInstance]{
			Client:         c,
			Scheme:         scheme,
			DefaultTimeout: 20 * time.Second,
			ControllerName: "litellminstance",
		},
	}
}

// +kubebuilder:rbac:groups=litellm.litellm.ai,resources=litellminstances,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups=litellm.litellm.ai,resources=litellminstances/status,verbs=get;update;patch
// +kubebuilder:rbac:groups=litellm.litellm.ai,resources=litellminstances/finalizers,verbs=update
// +kubebuilder:rbac:groups=core,resources=configmaps,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups=core,resources=secrets,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups=apps,resources=deployments,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups=core,resources=services,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups=networking.k8s.io,resources=ingresses,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups=core,resources=serviceaccounts,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups=rbac.authorization.k8s.io,resources=roles,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups=rbac.authorization.k8s.io,resources=rolebindings,verbs=get;list;watch;create;update;patch;delete

// Reconcile moves the current state of the cluster closer to the desired state.
// It creates or updates all required Kubernetes resources for a LiteLLMInstance:
// ConfigMap, Secret, Deployment, Service, and optionally Ingress.
func (r *LiteLLMInstanceReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) {
	log := logf.FromContext(ctx)
	// Instrument the reconcile loop
	r.InstrumentReconcileLoop()
	timer := r.InstrumentReconcileLatency()
	defer timer.ObserveDuration()

	//Phase 1: Fetch and validate the resource
	llm := &litellmv1alpha1.LiteLLMInstance{}
	llm, err := r.FetchResource(ctx, req.NamespacedName, llm)
	if err != nil {
		log.Error(err, "Failed to get LiteLLMInstance")
		r.InstrumentReconcileError()
		return ctrl.Result{}, err
	}
	if llm == nil {
		return ctrl.Result{}, nil
	}

	log.Info("Reconciling external LiteLLM instance resource", "litellmInstance", llm.Name) // Add timeout to avoid long-running reconciliation
	//Phase 2: Setup connections and clients
	r.ensureConnectionSetup(llm)

	// Phase 3: Handle deletion if resource is being deleted
	if !llm.DeletionTimestamp.IsZero() {
		return r.handleDeletion(ctx, llm)
	}

	// Phase 4: Ensure finalizer
	if err := r.AddFinalizer(ctx, llm, util.FinalizerName); err != nil {
		r.InstrumentReconcileError()
		return ctrl.Result{}, nil
	}

	// Phase 5 : Ensure external resource (create/patch/repair drift)
	if res, err := r.ensureExternal(ctx, llm); err != nil {
		r.InstrumentReconcileError()
		return res, err
	}

	// Phase 6 : Ensure in-cluster children (owned -> GC on delete)
	if _, err := r.ensureChildren(ctx, llm); err != nil {
		return r.HandleCommonErrors(ctx, llm, err)
	}

	// Phase 7: Mark Ready and persist ObservedGeneration
	latest := &litellmv1alpha1.LiteLLMInstance{}
	if err := r.Get(ctx, client.ObjectKey{Name: llm.Name, Namespace: llm.Namespace}, latest); err != nil {
		log.Error(err, "Failed to get latest version for final status update")
		return r.HandleErrorRetryable(ctx, llm, err, base.ReasonReconcileError)
	}

	// Copy resource-created flags from the working copy (ensureChildren patched them earlier)
	latest.Status.ConfigMapCreated = llm.Status.ConfigMapCreated
	latest.Status.SecretCreated = llm.Status.SecretCreated
	latest.Status.DeploymentCreated = llm.Status.DeploymentCreated
	latest.Status.ServiceCreated = llm.Status.ServiceCreated
	latest.Status.IngressCreated = llm.Status.IngressCreated

	if err := r.updateStatus(ctx, latest); err != nil {
		log.Error(err, "Failed to update status in Phase 7")
		return r.HandleErrorRetryable(ctx, latest, err, base.ReasonReconcileError)
	}

	log.Info("Reconciliation complete, litellmInstance is in desired state", "litellmInstance", llm.Name)
	// Phase 8: Periodic drift sync
	return ctrl.Result{RequeueAfter: 60 * time.Second}, nil
}

func (r *LiteLLMInstanceReconciler) ensureConnectionSetup(llm *litellmv1alpha1.LiteLLMInstance) {
	// Setup connections and clients.
	if r.litellmResourceNaming == nil {
		r.litellmResourceNaming = util.NewLitellmResourceNaming(llm.Name)
	}
}

// createOrUpdateResource handles common operations for creating or updating Kubernetes resources.
// It sets controller reference, applies the resource, and logs the operation.
// Returns the resource and any error that occurred.
func (r *LiteLLMInstanceReconciler) createOrUpdateResource(
	ctx context.Context,
	llm *litellmv1alpha1.LiteLLMInstance,
	resource client.Object,
	resourceType string) (client.Object, bool, error) {

	log := logf.FromContext(ctx)

	// Set controller reference so resource is owned and will be garbage collected
	if err := controllerutil.SetControllerReference(llm, resource, r.Scheme); err != nil {
		log.Error(err, "Failed to set controller reference", "resourceType", resourceType)
		return nil, false, fmt.Errorf("failed to set controller reference on %s: %w", resourceType, err)
	}

	// Create or update the resource with retry logic
	result, err := util.CreateOrUpdateWithRetry(ctx, r.Client, r.Scheme, resource, llm)
	if err != nil {
		log.Error(err, "Failed to create or update resource", "resourceType", resourceType)
		return nil, false, fmt.Errorf("failed to create or update %s: %w", resourceType, err)
	}

	log.V(1).Info("Successfully created or updated resource",
		"resourceType", resourceType,
		"name", resource.GetName(),
		"namespace", resource.GetNamespace(),
		"operation", result)

	return resource, result, nil
}

func (r *LiteLLMInstanceReconciler) ensureExternal(ctx context.Context, llm *litellmv1alpha1.LiteLLMInstance) (ctrl.Result, error) {
	_, err := validateModelListForDuplicates(llm.Spec.Models)
	if err != nil {
		return r.HandleErrorFinal(ctx, llm, err, "LLM Instance Spec is invalid")
	}

	return ctrl.Result{}, nil
}

func (r *LiteLLMInstanceReconciler) ensureChildren(ctx context.Context, llm *litellmv1alpha1.LiteLLMInstance) (ctrl.Result, error) {
	log := logf.FromContext(ctx)

	_, err := r.createConfigMap(ctx, llm)
	if err != nil {
		log.Error(err, "Failed to create or update ConfigMap")
		return r.HandleErrorRetryable(ctx, llm, err, base.ReasonReconcileError)
	}

	_, err = r.createMasterKeySecret(ctx, llm)
	if err != nil {
		log.Error(err, "Failed to create or update Secret")
		return r.HandleErrorRetryable(ctx, llm, err, base.ReasonReconcileError)
	}

	_, err = r.createServiceAccount(ctx, llm)
	if err != nil {
		log.Error(err, "Failed to create or update ServiceAccount")
		return r.HandleErrorRetryable(ctx, llm, err, base.ReasonReconcileError)
	}

	if err := r.createRBAC(ctx, llm); err != nil {
		log.Error(err, "Failed to create RBAC resources")
		return r.HandleErrorRetryable(ctx, llm, err, base.ReasonReconcileError)
	}

	_, err = r.createDeployment(ctx, llm)
	if err != nil {
		log.Error(err, "Failed to create or update Deployment")
		return r.HandleErrorRetryable(ctx, llm, err, base.ReasonReconcileError)
	}

	_, err = r.createService(ctx, llm)
	if err != nil {
		log.Error(err, "Failed to create or update Service")
		return r.HandleErrorRetryable(ctx, llm, err, base.ReasonReconcileError)
	}

	if llm.Spec.Ingress.Enabled {
		if err := r.createIngress(ctx, llm); err != nil {
			log.Error(err, "Failed to create or update Ingress")
			return r.HandleErrorRetryable(ctx, llm, err, base.ReasonReconcileError)
		}
	}

	// Before updating status, get the latest version of the resource to avoid conflicts
	latest := &litellmv1alpha1.LiteLLMInstance{}
	if err := r.Get(ctx, client.ObjectKey{Name: llm.Name, Namespace: llm.Namespace}, latest); err != nil {
		log.Error(err, "Failed to get latest version of resource before updating status")
		return r.HandleErrorRetryable(ctx, llm, err, base.ReasonReconcileError)
	}

	// Copy only the resource-created flags from our working copy to the latest version
	// We persist these booleans but we avoid computing/updating overall conditions here.
	original := latest.DeepCopy()
	latest.Status.ConfigMapCreated = llm.Status.ConfigMapCreated
	latest.Status.SecretCreated = llm.Status.SecretCreated
	latest.Status.DeploymentCreated = llm.Status.DeploymentCreated
	latest.Status.ServiceCreated = llm.Status.ServiceCreated
	latest.Status.IngressCreated = llm.Status.IngressCreated

	// Patch only the status subresource for the updated boolean flags to avoid
	// recalculating or setting the overall Ready condition here. Phase 7 (in Reconcile)
	// will be responsible for setting the overall success condition and ObservedGeneration.
	if err := r.PatchStatusFrom(ctx, original, latest); err != nil {
		log.Error(err, "Failed to patch status booleans after ensuring children")
		return r.HandleErrorRetryable(ctx, latest, err, base.ReasonReconcileError)
	}

	return ctrl.Result{}, nil
}

// handleDeletion removes the finalizer to allow the resource to be fully deleted.
func (r *LiteLLMInstanceReconciler) handleDeletion(ctx context.Context, llm *litellmv1alpha1.LiteLLMInstance) (ctrl.Result, error) {
	log := logf.FromContext(ctx)

	if !r.HasFinalizer(llm, util.FinalizerName) {
		return ctrl.Result{}, nil
	}

	// When handling deletion, get the latest version to avoid conflicts
	latest := &litellmv1alpha1.LiteLLMInstance{}
	if err := r.Get(ctx, client.ObjectKey{Name: llm.Name, Namespace: llm.Namespace}, latest); err != nil {
		if !errors.Is(err, client.IgnoreNotFound(err)) {
			log.Error(err, "Failed to get latest version during deletion", "name", llm.Name)
		}
		// Continue with deletion even if we can't update the status
	} else {
		r.SetCondition(latest, base.CondReady, metav1.ConditionFalse, base.ReasonDeleting, "LiteLLM Instance is being deleted")
		if err := r.Status().Update(ctx, latest); err != nil {
			log.Error(err, "Failed to update status during deletion", "name", latest.Name)
			// Continue with deletion even if status update fails
		}
		// Use the latest version for finalizer removal
		llm = latest
	}

	// Remove finalizer if it exists
	if err := r.RemoveFinalizer(ctx, llm, util.FinalizerName); err != nil {
		log.Error(err, "Failed to remove finalizer during deletion")
		return r.HandleErrorRetryable(ctx, llm, err, base.ReasonDeleteFailed)
	}

	log.Info("LiteLLMInstance successfully deleted", "name", llm.Name, "namespace", llm.Namespace)
	return ctrl.Result{}, nil
}

func validateModelListForDuplicates(llmModelList []litellmv1alpha1.InitModelInstance) (bool, error) {
	seen := make(map[string]bool)

	for _, model := range llmModelList {
		if seen[model.Identifier] {
			err := fmt.Errorf("LLM Instance model list contains duplicate identifiers %s", model.Identifier)
			return false, err
		}
		seen[model.Identifier] = true
	}

	return true, nil
}

// Shared function parseAndAssign moved to controller.go

// renderProxyConfig generates the YAML configuration for the LiteLLM proxy server.
// It creates a configuration structure with model list, router settings, and general settings.
func renderProxyConfig(llm *litellmv1alpha1.LiteLLMInstance, ctx context.Context, k8sClient client.Client, scheme *runtime.Scheme) (string, error) {
	log := logf.FromContext(ctx)

	var modelListYAML []ModelListItemYAML
	if llm.Spec.Models != nil {
		for _, model := range llm.Spec.Models {

			if model.LiteLLMParams.Model == nil || *model.LiteLLMParams.Model == "" {
				err := fmt.Errorf("model name is required for each model in the list")
				log.Error(err, "Failed to render proxy config")
				return "", err
			}

			//map all LiteLLMParams to the YAML struct
			litellmParams := LiteLLMParamsYAML{
				ApiKey:                         util.DerefString(model.LiteLLMParams.ApiKey),
				ApiBase:                        util.DerefString(model.LiteLLMParams.ApiBase),
				AwsAccessKeyID:                 util.DerefString(model.LiteLLMParams.AwsAccessKeyID),
				AwsSecretAccessKey:             util.DerefString(model.LiteLLMParams.AwsSecretAccessKey),
				AwsRegionName:                  util.DerefString(model.LiteLLMParams.AwsRegionName),
				AutoRouterConfigPath:           util.DerefString(model.LiteLLMParams.AutoRouterConfigPath),
				AutoRouterConfig:               util.DerefString(model.LiteLLMParams.AutoRouterConfig),
				AutoRouterDefaultModel:         util.DerefString(model.LiteLLMParams.AutoRouterDefaultModel),
				AutoRouterEmbeddingModel:       util.DerefString(model.LiteLLMParams.AutoRouterEmbeddingModel),
				ApiVersion:                     util.DerefString(model.LiteLLMParams.ApiVersion),
				BudgetDuration:                 util.DerefString(model.LiteLLMParams.BudgetDuration),
				CustomLLMProvider:              util.DerefString(model.LiteLLMParams.CustomLLMProvider),
				LiteLLMTraceID:                 util.DerefString(model.LiteLLMParams.LiteLLMTraceID),
				LiteLLMCredentialName:          util.DerefString(model.LiteLLMParams.LiteLLMCredentialName),
				MergeReasoningContentInChoices: util.DerefBool(model.LiteLLMParams.MergeReasoningContentInChoices),
				MockResponse:                   util.DerefString(model.LiteLLMParams.MockResponse),
				Model:                          util.DerefString(model.LiteLLMParams.Model),
				MaxRetries:                     util.DerefInt(model.LiteLLMParams.MaxRetries),
				MaxFileSizeMB:                  util.DerefInt(model.LiteLLMParams.MaxFileSizeMB),
				Organization:                   util.DerefString(model.LiteLLMParams.Organization),
				RegionName:                     util.DerefString(model.LiteLLMParams.RegionName),
				RPM:                            util.DerefInt(model.LiteLLMParams.RPM),
				StreamTimeout:                  util.DerefInt(model.LiteLLMParams.StreamTimeout),
				TPM:                            util.DerefInt(model.LiteLLMParams.TPM),
				Timeout:                        util.DerefInt(model.LiteLLMParams.Timeout),
				UseInPassThrough:               util.DerefBool(model.LiteLLMParams.UseInPassThrough),
				UseLiteLLMProxy:                util.DerefBool(model.LiteLLMParams.UseLiteLLMProxy),
				VertexProject:                  util.DerefString(model.LiteLLMParams.VertexProject),
				VertexLocation:                 util.DerefString(model.LiteLLMParams.VertexLocation),
				VertexCredentials:              util.DerefString(model.LiteLLMParams.VertexCredentials),
				WatsonxRegionName:              util.DerefString(model.LiteLLMParams.WatsonXRegionName),
			}

			if err := common.ParseAndAssign(model.LiteLLMParams.OutputCostPerToken, &litellmParams.OutputCostPerToken, "OutputCostPerToken"); err != nil {
				log.Error(err, "parsing error")
				return "", err
			}
			if err := common.ParseAndAssign(model.LiteLLMParams.OutputCostPerSecond, &litellmParams.OutputCostPerSecond, "OutputCostPerSecond"); err != nil {
				log.Error(err, "parsing error")
				return "", err
			}
			if err := common.ParseAndAssign(model.LiteLLMParams.OutputCostPerPixel, &litellmParams.OutputCostPerPixel, "OutputCostPerPixel"); err != nil {
				log.Error(err, "parsing error")
				return "", err
			}
			if err := common.ParseAndAssign(model.LiteLLMParams.InputCostPerPixel, &litellmParams.InputCostPerPixel, "InputCostPerPixel"); err != nil {
				log.Error(err, "parsing error")
				return "", err
			}
			if err := common.ParseAndAssign(model.LiteLLMParams.InputCostPerSecond, &litellmParams.InputCostPerSecond, "InputCostPerSecond"); err != nil {
				log.Error(err, "parsing error")
				return "", err
			}
			if err := common.ParseAndAssign(model.LiteLLMParams.InputCostPerToken, &litellmParams.InputCostPerToken, "InputCostPerToken"); err != nil {
				log.Error(err, "parsing error")
				return "", err
			}
			if err := common.ParseAndAssign(model.LiteLLMParams.MaxBudget, &litellmParams.MaxBudget, "MaxBudget"); err != nil {
				log.Error(err, "parsing error")
				return "", err
			}

			if model.LiteLLMParams.ConfigurableClientsideAuthParams != nil && len(*model.LiteLLMParams.ConfigurableClientsideAuthParams) > 0 {
				litellmParams.ConfigurableClientsideAuthParams = make([]interface{}, len(*model.LiteLLMParams.ConfigurableClientsideAuthParams))
				for i, param := range *model.LiteLLMParams.ConfigurableClientsideAuthParams {
					litellmParams.ConfigurableClientsideAuthParams[i] = param
				}
			}

			// If the model requires authentication, create individual secrets for each model
			if model.RequiresAuth {
				//get existing modelCredentials secret
				modelCredentials := &corev1.Secret{}
				err := k8sClient.Get(ctx, client.ObjectKey{Name: model.ModelCredentials.NameRef, Namespace: llm.Namespace}, modelCredentials)
				if err != nil {
					log.Error(err, "Model Credentials not found", "modelIdentifier", model.Identifier)
					return "", nil
				}

				//create individual secrets from the ModelCredentials
				secretNames, err := createAdditionalModelSecrets(ctx, &model, modelCredentials, llm, k8sClient, scheme)
				if err != nil {
					log.Error(err, "Failed to create secrets", "modelIdentifier", model.Identifier)
				}

				secretPrefix := "os.environ/"
				keys := model.ModelCredentials.Keys
				//match the secret to its yaml config to populate the yaml template
				fieldMap := map[string]*string{
					keys.VertexCredentials:  &litellmParams.VertexCredentials,
					keys.ApiBase:            &litellmParams.ApiBase,
					keys.AwsAccessKeyID:     &litellmParams.AwsAccessKeyID,
					keys.AwsSecretAccessKey: &litellmParams.AwsSecretAccessKey,
					keys.VertexProject:      &litellmParams.VertexCredentials,
					keys.ApiKey:             &litellmParams.ApiKey,
				}

				for key, target := range fieldMap {
					if key != "" {
						if secretName, ok := secretNames[key]; ok {
							*target = secretPrefix + secretName
						}
					}
				}

			}

			// Append a short tag to indicate this model was created from a LiteLLMInstance modelList
			modelYAML := ModelListItemYAML{
				ModelName:     common.AppendModelSourceTag(model.ModelName, common.ModelTagInst),
				LitellmParams: litellmParams,
			}
			modelListYAML = append(modelListYAML, modelYAML)
		}
	}

	var routerSettings RouterSettingsYAML
	if llm.Spec.RedisSecretRef.NameRef != "" {
		routerSettings = RouterSettingsYAML{
			Host:     llm.Spec.RedisSecretRef.Keys.HostSecret,
			Port:     llm.Spec.RedisSecretRef.Keys.PortSecret,
			Password: llm.Spec.RedisSecretRef.Keys.PasswordSecret,
		}
	}

	cfg := ProxyConfig{ModelList: modelListYAML, RouterSettings: routerSettings}
	cfg.GeneralSettings.AllowRequestsOnDBUnavailable = true
	cfg.GeneralSettings.StoreModelInDB = true

	b, _ := yaml.Marshal(cfg)
	return string(b), nil
}

// buildSecretData builds the secret data map for the LiteLLM instance.
// It handles the master key, either using the provided key or preserving an existing one.
func buildSecretData(masterKey string, existingSecret *corev1.Secret) map[string][]byte {
	data := make(map[string][]byte)

	// If no master key is provided, try to preserve existing one
	if masterKey == "" {
		if existingSecret != nil && existingSecret.Data != nil {
			if existingMasterKey, exists := existingSecret.Data["masterkey"]; exists {
				// Preserve existing master key
				data["masterkey"] = existingMasterKey
				return data
			}
		}
		// Generate a new random master key if none exists
		masterKey = "sk-" + uuid.New().String()
	}

	// Add master key (either provided or generated)
	if masterKey != "" {
		data["masterkey"] = []byte(masterKey)
	}

	return data
}

// updateStatus updates the LiteLLM instance status with current information.
// It updates observed generation, last updated timestamp, resource creation status, and conditions.
// Returns a combined status indicating whether all resources are ready.
func (r *LiteLLMInstanceReconciler) updateStatus(ctx context.Context, llm *litellmv1alpha1.LiteLLMInstance) error {
	log := logf.FromContext(ctx)

	// Update observed generation and last updated timestamp
	llm.Status.ObservedGeneration = llm.Generation
	now := metav1.Now()
	llm.Status.LastUpdated = &now

	// Update conditions
	r.updateConditions(ctx, llm)
	log.V(1).Info("Updating status conditions", "conditions", llm.Status.Conditions)

	// Use Status().Update which is more direct and simple
	// We're already using the latest version of the resource from the API server
	if err := r.Status().Update(ctx, llm); err != nil {
		log.Error(err, "Failed to update status",
			"name", llm.Name,
			"namespace", llm.Namespace,
			"resourceVersion", llm.GetResourceVersion())
		return err
	}

	log.Info("Status update successful", "name", llm.Name, "namespace", llm.Namespace)
	return nil
}

// childResourcesAreReady checks if all child resources are ready based on the status fields.
func (r *LiteLLMInstanceReconciler) childResourcesAreReady(llm *litellmv1alpha1.LiteLLMInstance) bool {
	// Use computed conditions to determine readiness to avoid mismatches
	required := []string{CondTypeConfigMapReady, CondTypeSecretReady, CondTypeDeploymentReady, CondTypeServiceReady}
	for _, t := range required {
		if !conditionIsTrue(llm, t) {
			return false
		}
	}

	if llm.Spec.Ingress.Enabled && !conditionIsTrue(llm, CondTypeIngressReady) {
		return false
	}

	return true
}

// conditionIsTrue returns true if the named condition exists on the resource and its Status is True.
func conditionIsTrue(llm *litellmv1alpha1.LiteLLMInstance, t string) bool {
	for _, c := range llm.Status.Conditions {
		if c.Type == t {
			return c.Status == metav1.ConditionTrue
		}
	}
	return false
}

// createCondition creates a standard condition with the given parameters.
// This helper function reduces duplication in condition creation.
func (r *LiteLLMInstanceReconciler) createCondition(
	conditionType string,
	gen int64,
	reason, message string,
) metav1.Condition {
	// Default new conditions to False; callers will flip to True when appropriate.
	return metav1.Condition{
		Type:               conditionType,
		Status:             metav1.ConditionFalse,
		ObservedGeneration: gen,
		LastTransitionTime: metav1.Now(),
		Reason:             reason,
		Message:            message,
	}
}

// updateConditions updates the conditions for the LiteLLM instance.
// It creates conditions for each resource type and an overall Ready condition.
func (r *LiteLLMInstanceReconciler) updateConditions(ctx context.Context, llm *litellmv1alpha1.LiteLLMInstance) {
	// ConfigMap ready condition
	configMapReady := r.createCondition(
		CondTypeConfigMapReady,
		llm.Generation,
		"ConfigMapNotReady",
		"ConfigMap is not ready",
	)

	if llm.Status.ConfigMapCreated {
		configMapReady.Status = metav1.ConditionTrue
		configMapReady.Reason = "ConfigMapReady"
		configMapReady.Message = "ConfigMap has been created"
	}

	// Secret ready condition
	secretReady := r.createCondition(
		CondTypeSecretReady,
		llm.Generation,
		"SecretNotReady",
		"Secret is not ready",
	)

	if llm.Status.SecretCreated {
		secretReady.Status = metav1.ConditionTrue
		secretReady.Reason = "SecretReady"
		secretReady.Message = "Secret has been created"
	}

	// Deployment ready condition
	deploymentReady := r.createCondition(
		CondTypeDeploymentReady,
		llm.Generation,
		"DeploymentNotReady",
		"Deployment is not ready",
	)

	// Check if deployment is actually ready
	deployment := &appsv1.Deployment{}
	err := r.Client.Get(ctx, client.ObjectKey{Name: r.litellmResourceNaming.GetDeploymentName(), Namespace: llm.Namespace}, deployment)
	if err != nil && !errors.Is(err, client.IgnoreNotFound(err)) {
		deploymentReady.Status = metav1.ConditionFalse
		deploymentReady.Reason = "DeploymentNotReady"
		deploymentReady.Message = fmt.Sprintf("Failed to get Deployment: %v", err)
	} else {
		expectedReplicas := int32(1) // Default to 1 replica as per createDeployment
		if deployment.Spec.Replicas != nil {
			expectedReplicas = *deployment.Spec.Replicas
		}

		if deployment.Status.ReadyReplicas >= expectedReplicas &&
			deployment.Status.AvailableReplicas >= expectedReplicas &&
			deployment.Status.UpdatedReplicas >= expectedReplicas {
			deploymentReady.Status = metav1.ConditionTrue
			deploymentReady.Reason = "DeploymentReady"
			deploymentReady.Message = fmt.Sprintf("Deployment has %d/%d ready replicas", deployment.Status.ReadyReplicas, expectedReplicas)
		} else {
			deploymentReady.Status = metav1.ConditionFalse
			deploymentReady.Reason = "DeploymentNotReady"
			deploymentReady.Message = fmt.Sprintf("Deployment has %d/%d ready replicas, %d/%d available, %d/%d updated",
				deployment.Status.ReadyReplicas, expectedReplicas,
				deployment.Status.AvailableReplicas, expectedReplicas,
				deployment.Status.UpdatedReplicas, expectedReplicas)
		}
	}

	// Service ready condition
	serviceReady := r.createCondition(
		CondTypeServiceReady,
		llm.Generation,
		"ServiceNotReady",
		"Service is not ready",
	)
	service := &corev1.Service{}
	err = r.Client.Get(ctx, client.ObjectKey{Name: r.litellmResourceNaming.GetServiceName(), Namespace: llm.Namespace}, service)
	if err != nil && !errors.Is(err, client.IgnoreNotFound(err)) {
		serviceReady.Status = metav1.ConditionFalse
		serviceReady.Reason = "ServiceNotReady"
		serviceReady.Message = fmt.Sprintf("Failed to get Service: %v", err)
	} else if service.Spec.ClusterIP != "" {
		serviceReady.Status = metav1.ConditionTrue
		serviceReady.Reason = "ServiceReady"
		serviceReady.Message = fmt.Sprintf("Service is ready with ClusterIP: %s", service.Spec.ClusterIP)
	}

	// Ingress ready condition (only if ingress is enabled)
	if llm.Spec.Ingress.Enabled {
		ingressReady := r.createCondition(
			CondTypeIngressReady,
			llm.Generation,
			"IngressNotReady",
			"Ingress is not ready",
		)

		if llm.Status.IngressCreated {
			ingressReady.Status = metav1.ConditionTrue
			ingressReady.Reason = "IngressReady"
			ingressReady.Message = "Ingress has been created"
		}

		r.setCondition(llm, ingressReady)
	}

	// Overall Ready condition
	ready := r.createCondition(
		"Ready",
		llm.Generation,
		"NotReady",
		"Not all resources are ready",
	)

	// Only set to True if ALL required resources are ready. Use helper so it's centralized.
	allReady := r.childResourcesAreReady(llm)

	if allReady {
		ready.Status = metav1.ConditionTrue
		ready.Reason = "Ready"
		ready.Message = "All resources are ready"
	}

	// Update or add conditions
	r.setCondition(llm, configMapReady)
	r.setCondition(llm, secretReady)
	r.setCondition(llm, deploymentReady)
	r.setCondition(llm, serviceReady)
	r.setCondition(llm, ready)

	// Emit metrics for resource active/inactive state and per-status counts
	// Best-effort: ignore metric errors
	r.updateResourceMetrics(llm)
}

// updateResourceMetrics updates Prometheus gauges describing managed resource state for this LiteLLMInstance.
// It sets litellm_managed_resource_active{instance,namespace,resource} to 1 when the resource is present/ready and 0 otherwise.
// It also sets litellm_managed_resource_status{instance,namespace,resource,status} where status is one of: created,missing,ready,not_ready
func (r *LiteLLMInstanceReconciler) updateResourceMetrics(llm *litellmv1alpha1.LiteLLMInstance) {
	// Helper to set active/state metrics for a named resource
	setMetrics := func(resource string, active bool, status string) {
		inst := llm.Name
		ns := llm.Namespace
		var a float64
		if active {
			a = 1
		} else {
			a = 0
		}
		managedResourceActive.WithLabelValues(inst, ns, resource).Set(a)

		// Ensure we zero other status labels except the current one. We will set the current one to 1 and others to 0
		// For simplicity, set current status to 1 and leave others to be zeroed on future updates.
		managedResourceStatus.WithLabelValues(inst, ns, resource, status).Set(1)
	}

	// ConfigMap
	cfgStatus := StatusMissing
	if llm.Status.ConfigMapCreated {
		cfgStatus = StatusCreated
	}
	// treat created as active for configmap
	setMetrics("configmap", llm.Status.ConfigMapCreated, cfgStatus)

	// Secret
	secretStatus := StatusMissing
	if llm.Status.SecretCreated {
		secretStatus = StatusCreated
	}
	setMetrics("secret", llm.Status.SecretCreated, secretStatus)

	// Deployment: derive ready/not_ready from conditions
	deployActive := conditionIsTrue(llm, CondTypeDeploymentReady)
	deployStatus := StatusNotReady
	if deployActive {
		deployStatus = StatusReady
	} else if llm.Status.DeploymentCreated {
		deployStatus = StatusCreated
	}
	setMetrics("deployment", llm.Status.DeploymentCreated, deployStatus)

	// Service
	svcActive := conditionIsTrue(llm, CondTypeServiceReady)
	svcStatus := StatusNotReady
	if svcActive {
		svcStatus = StatusReady
	} else if llm.Status.ServiceCreated {
		svcStatus = StatusCreated
	}
	setMetrics("service", llm.Status.ServiceCreated, svcStatus)

	// Ingress (if enabled)
	if llm.Spec.Ingress.Enabled {
		ingActive := conditionIsTrue(llm, CondTypeIngressReady)
		ingStatus := StatusNotReady
		if ingActive {
			ingStatus = StatusReady
		} else if llm.Status.IngressCreated {
			ingStatus = StatusCreated
		}
		setMetrics("ingress", llm.Status.IngressCreated, ingStatus)
	}

	// Overall instance readiness
	readyActive := conditionIsTrue(llm, "Ready")
	readyStatus := StatusNotReady
	if readyActive {
		readyStatus = StatusReady
	}
	setMetrics("instance", readyActive, readyStatus)
}

func (r *LiteLLMInstanceReconciler) setCondition(llm *litellmv1alpha1.LiteLLMInstance, condition metav1.Condition) {
	// record old slice for change detection
	old := make([]metav1.Condition, len(llm.Status.Conditions))
	copy(old, llm.Status.Conditions)

	// use the k8s helper which updates LastTransitionTime appropriately
	meta.SetStatusCondition(&llm.Status.Conditions, condition)
}

// createConfigMap creates or updates the ConfigMap for the LiteLLM instance.
// It generates the LiteLLM proxy configuration and creates a ConfigMap containing the configuration file.
func (r *LiteLLMInstanceReconciler) createConfigMap(ctx context.Context, llm *litellmv1alpha1.LiteLLMInstance) (*corev1.ConfigMap, error) {
	log := logf.FromContext(ctx)

	configYAML, err := renderProxyConfig(llm, ctx, r.Client, r.Scheme)
	if err != nil {
		log.Error(err, "Failed to render proxy config")
		return nil, err
	}

	configMap := &corev1.ConfigMap{
		ObjectMeta: metav1.ObjectMeta{
			Name:      r.litellmResourceNaming.GetConfigMapName(),
			Namespace: llm.Namespace,
		},
		Data: map[string]string{"proxy_server_config.yaml": configYAML},
	}

	_, restart, err := r.createOrUpdateResource(ctx, llm, configMap, "ConfigMap")
	if err != nil {
		return nil, err
	}

	// Check if we need to restart the deployment due to config changes
	if restart {
		// Get the deployment
		deployment := &appsv1.Deployment{}
		err := r.Get(ctx, client.ObjectKey{Name: r.litellmResourceNaming.GetDeploymentName(), Namespace: llm.Namespace}, deployment)
		if err != nil {
			return nil, err
		}
		log.Info("Restarting deployment", "deployment", deployment.Name)
		if err := util.RestartDeployment(ctx, r.Client, deployment.Name, deployment.Namespace); err != nil {
			log.Error(err, "Failed to restart deployment", "deployment", deployment.Name)
			return nil, err
		}
	}

	// set ConfigMapCreated status
	llm.Status.ConfigMapCreated = true

	return configMap, nil
}

// sanitizes a key to a string that conforms with Kubernetes secret naming conventions
func sanitizeKey(key string) string {
	// Convert to lowercase
	key = strings.ToLower(key)

	// Replace any character that is not a-z, 0-9, or '-' with hyphen
	reg := regexp.MustCompile(`[^a-z0-9-]+`)
	sanitized := reg.ReplaceAllString(key, "-")

	// Trim leading/trailing hyphens or dots
	sanitized = strings.Trim(sanitized, "-.")

	// Ensure it starts and ends with an alphanumeric character
	startEndReg := regexp.MustCompile(`^[^a-z0-9]+|[^a-z0-9]+$`)
	sanitized = startEndReg.ReplaceAllString(sanitized, "")

	// Truncate to 253 characters if necessary
	if len(sanitized) > 253 {
		sanitized = sanitized[:253]
	}

	return sanitized
}

func createAdditionalModelSecrets(ctx context.Context, model *litellmv1alpha1.InitModelInstance, modelCredentials *corev1.Secret, llm *litellmv1alpha1.LiteLLMInstance,
	k8sClient client.Client, scheme *runtime.Scheme) (map[string]string, error) {

	log := logf.FromContext(ctx)
	secretNames := map[string]string{}
	for key, value := range modelCredentials.Data {
		secretName := sanitizeKey(fmt.Sprintf("%s_%s", model.Identifier, key))
		data := map[string][]byte{key: value}

		_, err := createSecret(ctx, k8sClient, scheme, secretName, modelCredentials.Namespace, data, llm)
		if err != nil {
			log.Error(err, "failed to create secret from ModelCredentials", "secretName", secretName)
			return nil, err
		}

		secretNames[key] = secretName
	}

	return secretNames, nil
}

// createSecret creates or updates the Secret for the LiteLLM instance.
// It creates a Secret containing the master key and other sensitive data.
func (r *LiteLLMInstanceReconciler) createMasterKeySecret(ctx context.Context, llm *litellmv1alpha1.LiteLLMInstance) (*corev1.Secret, error) {
	// Get existing secret to preserve data if it exists
	secretName := r.litellmResourceNaming.GetSecretName()
	existingSecret := &corev1.Secret{}
	err := r.Get(ctx, client.ObjectKey{Name: secretName, Namespace: llm.Namespace}, existingSecret)
	if err != nil && client.IgnoreNotFound(err) != nil {
		return nil, err
	}

	data := buildSecretData(llm.Spec.MasterKey, existingSecret)

	secret := &corev1.Secret{
		ObjectMeta: metav1.ObjectMeta{
			Name:      secretName,
			Namespace: llm.Namespace,
		},
		Type: corev1.SecretTypeOpaque,
		Data: data,
	}

	resource, _, err := r.createOrUpdateResource(ctx, llm, secret, "Secret")
	if err != nil {
		return nil, err
	}

	// set SecretCreated status
	llm.Status.SecretCreated = true

	return resource.(*corev1.Secret), nil
}

func createSecret(ctx context.Context, k8sClient client.Client, scheme *runtime.Scheme, name string, namespace string, data map[string][]byte, owner client.Object) (*corev1.Secret, error) {
	secret := &corev1.Secret{
		ObjectMeta: metav1.ObjectMeta{
			Name:      name,
			Namespace: namespace,
		},
		Type: corev1.SecretTypeOpaque,
		Data: data,
	}

	// set owner ref before create so GC sees the owner
	if owner != nil {
		if err := controllerutil.SetControllerReference(owner, secret, scheme); err != nil {
			return nil, err
		}
	}

	if _, err := util.CreateOrUpdateWithRetry(ctx, k8sClient, scheme, secret, owner); err != nil {
		return nil, err
	}

	return secret, nil
}

// createDeployment creates or updates the Deployment for the LiteLLM instance.
// It creates a Deployment that runs the LiteLLM proxy container with appropriate configuration.
func (r *LiteLLMInstanceReconciler) createDeployment(ctx context.Context, llm *litellmv1alpha1.LiteLLMInstance) (*appsv1.Deployment, error) {
	log := logf.FromContext(ctx)

	deployment := &appsv1.Deployment{
		ObjectMeta: metav1.ObjectMeta{
			Name:      r.litellmResourceNaming.GetDeploymentName(),
			Namespace: llm.Namespace,
			Labels:    r.litellmResourceNaming.GetAppLabels(),
		},
		Spec: appsv1.DeploymentSpec{
			Replicas: util.Int32Ptr(llm.Spec.Replicas),
			Selector: &metav1.LabelSelector{
				MatchLabels: r.litellmResourceNaming.GetAppLabels(),
			},
			Template: corev1.PodTemplateSpec{
				ObjectMeta: metav1.ObjectMeta{
					Labels: r.litellmResourceNaming.GetAppLabels(),
				},
				Spec: corev1.PodSpec{
					ServiceAccountName: r.litellmResourceNaming.GetServiceAccountName(),
					Containers: []corev1.Container{
						buildContainerSpec(llm, r.litellmResourceNaming.GetSecretName(), ctx, r.Client),
					},
					Volumes: []corev1.Volume{
						{
							Name: "config-volume",
							VolumeSource: corev1.VolumeSource{
								ConfigMap: &corev1.ConfigMapVolumeSource{
									LocalObjectReference: corev1.LocalObjectReference{
										Name: r.litellmResourceNaming.GetConfigMapName(),
									},
								},
							},
						},
					},
				},
			},
		},
	}
	log.V(1).Info("Creating or updating deployment", "deployment", deployment.Name)

	resource, _, err := r.createOrUpdateResource(ctx, llm, deployment, "Deployment")
	if err != nil {
		return nil, err
	}

	// set deployment status
	llm.Status.DeploymentCreated = true

	return resource.(*appsv1.Deployment), nil
}

// createService creates or updates the Service for the LiteLLM instance.
// It creates a Service that exposes the LiteLLM proxy on port 80.
func (r *LiteLLMInstanceReconciler) createService(ctx context.Context, llm *litellmv1alpha1.LiteLLMInstance) (*corev1.Service, error) {
	service := &corev1.Service{
		ObjectMeta: metav1.ObjectMeta{
			Name:      r.litellmResourceNaming.GetServiceName(),
			Namespace: llm.Namespace,
			Labels:    r.litellmResourceNaming.GetAppLabels(),
		},
		Spec: corev1.ServiceSpec{
			Selector: r.litellmResourceNaming.GetAppLabels(),
			Ports: []corev1.ServicePort{
				{
					Name:       "http",
					Protocol:   corev1.ProtocolTCP,
					Port:       ServicePort,
					TargetPort: intstr.FromInt(ContainerPort),
				},
			},
			Type: corev1.ServiceTypeClusterIP,
		},
	}

	resource, _, err := r.createOrUpdateResource(ctx, llm, service, "Service")
	if err != nil {
		return nil, err
	}

	llm.Status.ServiceCreated = true

	return resource.(*corev1.Service), nil
}

// createServiceAccount creates or updates the ServiceAccount for the LiteLLM instance.
// It creates a ServiceAccount that the Deployment will use.
func (r *LiteLLMInstanceReconciler) createServiceAccount(ctx context.Context, llm *litellmv1alpha1.LiteLLMInstance) (*corev1.ServiceAccount, error) {
	serviceAccount := &corev1.ServiceAccount{
		ObjectMeta: metav1.ObjectMeta{
			Name:      r.litellmResourceNaming.GetServiceAccountName(),
			Namespace: llm.Namespace,
			Labels:    r.litellmResourceNaming.GetAppLabels(),
		},
	}

	resource, _, err := r.createOrUpdateResource(ctx, llm, serviceAccount, "ServiceAccount")
	if err != nil {
		return nil, err
	}

	return resource.(*corev1.ServiceAccount), nil
}

// createRBAC creates or updates the Role and RoleBinding for the LiteLLM instance ServiceAccount.
// It creates a Role with minimal permissions and a RoleBinding to bind it to the ServiceAccount.
func (r *LiteLLMInstanceReconciler) createRBAC(ctx context.Context, llm *litellmv1alpha1.LiteLLMInstance) error {
	// Create Role with minimal permissions for the LiteLLM instance
	role := &rbacv1.Role{
		ObjectMeta: metav1.ObjectMeta{
			Name:      r.litellmResourceNaming.GetRoleName(),
			Namespace: llm.Namespace,
			Labels:    r.litellmResourceNaming.GetAppLabels(),
		},
		Rules: []rbacv1.PolicyRule{
			{
				APIGroups: []string{""},
				Resources: []string{"configmaps", "secrets"},
				Verbs:     []string{"get", "list", "watch"},
			},
		},
	}

	_, _, err := r.createOrUpdateResource(ctx, llm, role, "Role")
	if err != nil {
		return err
	}

	// Create RoleBinding to bind the Role to the ServiceAccount
	roleBinding := &rbacv1.RoleBinding{
		ObjectMeta: metav1.ObjectMeta{
			Name:      r.litellmResourceNaming.GetRoleBindingName(),
			Namespace: llm.Namespace,
			Labels:    r.litellmResourceNaming.GetAppLabels(),
		},
		Subjects: []rbacv1.Subject{
			{
				Kind:      "ServiceAccount",
				Name:      r.litellmResourceNaming.GetServiceAccountName(),
				Namespace: llm.Namespace,
			},
		},
		RoleRef: rbacv1.RoleRef{
			APIGroup: "rbac.authorization.k8s.io",
			Kind:     "Role",
			Name:     role.Name,
		},
	}

	_, _, err = r.createOrUpdateResource(ctx, llm, roleBinding, "RoleBinding")
	if err != nil {
		return err
	}

	return nil
}

// createIngress creates or updates the Ingress for the LiteLLM instance.
// It creates an Ingress resource to expose the LiteLLM proxy externally when enabled.
func (r *LiteLLMInstanceReconciler) createIngress(ctx context.Context, llm *litellmv1alpha1.LiteLLMInstance) error {
	ingress := &networkingv1.Ingress{
		ObjectMeta: metav1.ObjectMeta{
			Name:      r.litellmResourceNaming.GetIngressName(),
			Namespace: llm.Namespace,
		},
		Spec: networkingv1.IngressSpec{
			Rules: []networkingv1.IngressRule{
				{
					Host: llm.Spec.Ingress.Host,
				},
			},
		},
	}

	_, _, err := r.createOrUpdateResource(ctx, llm, ingress, "Ingress")
	if err != nil {
		return err
	}

	llm.Status.IngressCreated = true

	return nil
}

// SetupWithManager sets up the controller with the Manager.
// It registers the controller with the controller-runtime manager and configures the watch.
func (r *LiteLLMInstanceReconciler) SetupWithManager(mgr ctrl.Manager) error {
	return ctrl.NewControllerManagedBy(mgr).
		For(&litellmv1alpha1.LiteLLMInstance{}).
		Named("litellm-litellminstance").
		Owns(&corev1.ConfigMap{}).
		Owns(&corev1.Secret{}).
		Owns(&appsv1.Deployment{}).
		Owns(&corev1.Service{}).
		Owns(&networkingv1.Ingress{}).
		Owns(&corev1.ServiceAccount{}).
		Owns(&rbacv1.Role{}).
		Owns(&rbacv1.RoleBinding{}).
		Complete(r)
}

// buildContainerSpec builds the container specification for the LiteLLM deployment.
// It creates a complete container spec with image, arguments, ports, environment variables, and health checks.
func buildContainerSpec(llm *litellmv1alpha1.LiteLLMInstance, secretName string, ctx context.Context, k8sClient client.Client) corev1.Container {
	return corev1.Container{
		Name:  "litellm",
		Image: llm.Spec.Image,
		Args:  []string{"--config", ConfigPath},
		Ports: []corev1.ContainerPort{
			{
				ContainerPort: ContainerPort,
			},
		},
		Env: buildEnvironmentVariables(llm, secretName, ctx, k8sClient),
		VolumeMounts: []corev1.VolumeMount{
			{
				Name:      "config-volume",
				MountPath: "/etc/litellm",
				ReadOnly:  true,
			},
		},
		LivenessProbe:  buildLivenessProbe(),
		ReadinessProbe: buildReadinessProbe(),
		StartupProbe:   buildStartupProbe(),
	}
}

// buildEnvironmentVariables builds the environment variables for the container.
// It creates environment variables for the LiteLLM master key and database connection details.
func buildEnvironmentVariables(llm *litellmv1alpha1.LiteLLMInstance, secretName string, ctx context.Context, k8sClient client.Client) []corev1.EnvVar {
	log := logf.FromContext(ctx)
	envVars := []corev1.EnvVar{
		{
			Name: "LITELLM_MASTER_KEY",
			ValueFrom: &corev1.EnvVarSource{
				SecretKeyRef: &corev1.SecretKeySelector{
					LocalObjectReference: corev1.LocalObjectReference{
						Name: secretName,
					},
					Key: "masterkey",
				},
			},
		},
	}

	// Add database environment variables if database secret reference is provided
	if llm.Spec.DatabaseSecretRef.NameRef != "" {
		dbEnvVars := []corev1.EnvVar{
			{
				Name: "DATABASE_NAME",
				ValueFrom: &corev1.EnvVarSource{
					SecretKeyRef: &corev1.SecretKeySelector{
						LocalObjectReference: corev1.LocalObjectReference{
							Name: llm.Spec.DatabaseSecretRef.NameRef,
						},
						Key: llm.Spec.DatabaseSecretRef.Keys.DbnameSecret,
					},
				},
			},
			{
				Name: "DATABASE_HOST",
				ValueFrom: &corev1.EnvVarSource{
					SecretKeyRef: &corev1.SecretKeySelector{
						LocalObjectReference: corev1.LocalObjectReference{
							Name: llm.Spec.DatabaseSecretRef.NameRef,
						},
						Key: llm.Spec.DatabaseSecretRef.Keys.HostSecret,
					},
				},
			},
			{
				Name: "DATABASE_PASSWORD",
				ValueFrom: &corev1.EnvVarSource{
					SecretKeyRef: &corev1.SecretKeySelector{
						LocalObjectReference: corev1.LocalObjectReference{
							Name: llm.Spec.DatabaseSecretRef.NameRef,
						},
						Key: llm.Spec.DatabaseSecretRef.Keys.PasswordSecret,
					},
				},
			},
			{
				Name: "DATABASE_USERNAME",
				ValueFrom: &corev1.EnvVarSource{
					SecretKeyRef: &corev1.SecretKeySelector{
						LocalObjectReference: corev1.LocalObjectReference{
							Name: llm.Spec.DatabaseSecretRef.NameRef,
						},
						Key: llm.Spec.DatabaseSecretRef.Keys.UsernameSecret,
					},
				},
			},
		}
		envVars = append(envVars, dbEnvVars...)

	}

	for _, model := range llm.Spec.Models {
		if !model.RequiresAuth {
			log.V(1).Info("model requires no auth, so skipping secret mounting!")
			continue
		}

		prefix := sanitizeKey(model.Identifier)
		modelSecrets, err := getAllSecretsByPrefix(ctx, k8sClient, llm.Namespace, prefix)
		if err != nil {
			log.Error(err, "Failed to retrieve secrets using model unique identifier")
			return nil
		}

		//add all secrets we created into the EnvVars using valueFrom
		for _, secret := range modelSecrets {
			envVars = append(envVars, corev1.EnvVar{
				Name: secret.Name, //will be used in proxy_server_config.yaml to reference secret
				ValueFrom: &corev1.EnvVarSource{
					SecretKeyRef: &corev1.SecretKeySelector{
						LocalObjectReference: corev1.LocalObjectReference{
							Name: secret.Name,
						},
						Key: func() string {
							for key := range secret.Data {
								return key // use the first key in the secret data
							}
							err := errors.New("failed to retrieve secret key")
							log.Error(err, "No keys found in secret", "secretName", secret.Name)
							return ""
						}(),
					},
				},
			})
		}
	}

	// Add extra environment variables
	envVars = append(envVars, llm.Spec.ExtraEnvVars...)

	return envVars
}

func getAllSecretsByPrefix(ctx context.Context, k8sClient client.Client, namespace string, prefix string) ([]corev1.Secret, error) {
	var allSecrets corev1.SecretList
	err := k8sClient.List(ctx, &allSecrets, client.InNamespace(namespace))
	if err != nil {
		return nil, err
	}

	var secrets []corev1.Secret
	for _, secret := range allSecrets.Items {
		if strings.HasPrefix(secret.Name, prefix) {
			secrets = append(secrets, secret)
		}
	}

	return secrets, nil
}

// buildLivenessProbe builds the liveness probe configuration.
// It creates a liveness probe that checks if the LiteLLM proxy is responding to health check requests.
func buildLivenessProbe() *corev1.Probe {
	return &corev1.Probe{
		ProbeHandler: corev1.ProbeHandler{
			HTTPGet: &corev1.HTTPGetAction{
				Path: LivenessPath,
				Port: util.FromInt(ContainerPort),
			},
		},
		InitialDelaySeconds: 60,
		PeriodSeconds:       30,
		TimeoutSeconds:      10,
		FailureThreshold:    3,
	}
}

// buildReadinessProbe builds the readiness probe configuration.
// It creates a readiness probe that checks if the LiteLLM proxy is ready to accept traffic.
func buildReadinessProbe() *corev1.Probe {
	return &corev1.Probe{
		ProbeHandler: corev1.ProbeHandler{
			HTTPGet: &corev1.HTTPGetAction{
				Path: ReadinessPath,
				Port: util.FromInt(ContainerPort),
			},
		},
		InitialDelaySeconds: 10,
		PeriodSeconds:       10,
		TimeoutSeconds:      5,
		FailureThreshold:    3,
	}
}

// buildStartupProbe builds the startup probe configuration.
// It creates a startup probe that checks if the LiteLLM proxy has finished starting up.
func buildStartupProbe() *corev1.Probe {
	return &corev1.Probe{
		ProbeHandler: corev1.ProbeHandler{
			HTTPGet: &corev1.HTTPGetAction{
				Path: ReadinessPath,
				Port: util.FromInt(ContainerPort),
			},
		},
		InitialDelaySeconds: 30,
		PeriodSeconds:       10,
		TimeoutSeconds:      5,
		FailureThreshold:    30,
	}
}
